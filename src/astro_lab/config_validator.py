"""Validate configuration consistency across all YAML files."""

from pathlib import Path
from typing import List, Tuple

from astro_lab.config import get_config

class ConfigValidator:
    """Validate AstroLab configuration files."""
    
    def __init__(self):
        self.configs = get_config()
        self.issues = []
        
    def validate_all(self) -> Tuple[bool, List[str]]:
        """Run all validation checks."""
        self.issues = []
        
        # Check individual configs
        self._validate_data_config()
        self._validate_model_config()
        self._validate_training_config()
        self._validate_survey_configs()
        self._validate_task_configs()
        
        # Check cross-config consistency
        self._validate_cross_config_consistency()
        
        return len(self.issues) == 0, self.issues
    
    def _validate_data_config(self):
        """Validate data configuration."""
        data = self.configs.get("data", {})
        
        # Check required fields
        required = ["base_dir", "processed_dir", "raw_dir"]
        for field in required:
            if field not in data:
                self.issues.append(f"data.yaml: Missing required field '{field}'")
        
        # Check paths exist
        for field in ["base_dir", "processed_dir", "raw_dir"]:
            if field in data:
                path = Path(data[field])
                # Only check base_dir existence, others are created on demand
                if field == "base_dir" and not path.exists():
                    self.issues.append(f"data.yaml: Base directory '{data[field]}' does not exist")
        
        # Validate numeric ranges
        if data.get("batch_size", 0) < 1:
            self.issues.append("data.yaml: batch_size must be >= 1")
        
        if data.get("k_neighbors", 0) < 1:
            self.issues.append("data.yaml: k_neighbors must be >= 1")
            
    def _validate_model_config(self):
        """Validate model configuration."""
        model = self.configs.get("model", {})
        
        # Check conv_type is valid
        valid_conv_types = ["gcn", "gat", "gin", "sage", "transformer", "pointnet", "temporal"]
        if "conv_type" in model and model["conv_type"] not in valid_conv_types:
            self.issues.append(
                f"model.yaml: conv_type '{model.get('conv_type')}' "
                f"not in {valid_conv_types}"
            )
        
        # Check numeric ranges
        if model.get("hidden_dim", 0) < 1:
            self.issues.append("model.yaml: hidden_dim must be >= 1")
            
        if model.get("num_layers", 0) < 1:
            self.issues.append("model.yaml: num_layers must be >= 1")
            
        if "dropout" in model and not 0 <= model["dropout"] <= 1:
            self.issues.append("model.yaml: dropout must be in [0, 1]")
    
    def _validate_training_config(self):
        """Validate training configuration."""
        training = self.configs.get("training", {})
        
        # Check numeric ranges
        if training.get("max_epochs", 0) < 1:
            self.issues.append("training.yaml: max_epochs must be >= 1")
            
        if training.get("learning_rate", 0) <= 0:
            self.issues.append("training.yaml: learning_rate must be > 0")
            
        # Validate precision values
        valid_precisions = ["32-true", "16-mixed", "bf16-mixed"]
        if "precision" in training and training["precision"] not in valid_precisions:
            self.issues.append(
                f"training.yaml: precision '{training['precision']}' "
                f"not in {valid_precisions}"
            )
    
    def _validate_survey_configs(self):
        """Validate each survey configuration."""
        surveys = self.configs.get("surveys", {})
        
        for survey_name, survey_config in surveys.items():
            # Check required fields
            required = ["name", "coord_cols", "mag_cols"]
            for field in required:
                if field not in survey_config:
                    self.issues.append(
                        f"surveys.yaml: Survey '{survey_name}' "
                        f"missing required field '{field}'"
                    )
            
            # Validate recommended model if present
            if "recommended_model" in survey_config:
                rec_model = survey_config["recommended_model"]
                
                if "conv_type" in rec_model:
                    valid_types = ["gcn", "gat", "gin", "sage", "transformer", "pointnet", "temporal"]
                    if rec_model["conv_type"] not in valid_types:
                        self.issues.append(
                            f"surveys.yaml: Survey '{survey_name}' has invalid "
                            f"recommended conv_type '{rec_model['conv_type']}'"
                        )
                
                # Check GAT/Transformer have heads
                if rec_model.get("conv_type") in ["gat", "transformer"]:
                    if "heads" not in rec_model:
                        self.issues.append(
                            f"surveys.yaml: Survey '{survey_name}' with "
                            f"{rec_model['conv_type']} should specify 'heads'"
                        )
    
    def _validate_task_configs(self):
        """Validate task configurations."""
        tasks = self.configs.get("tasks", {})
        
        valid_tasks = ["node_classification", "graph_classification", 
                      "node_regression", "graph_regression", "link_prediction"]
        
        for task_name, task_config in tasks.items():
            if task_name not in valid_tasks:
                self.issues.append(
                    f"tasks.yaml: Unknown task '{task_name}'"
                )
            
            # Check task consistency
            if task_config.get("task") != task_name:
                self.issues.append(
                    f"tasks.yaml: Task '{task_name}' has mismatched "
                    f"task field '{task_config.get('task')}'"
                )
            
            # Graph tasks should have pooling
            if "graph" in task_name and not task_config.get("pooling"):
                self.issues.append(
                    f"tasks.yaml: Graph task '{task_name}' should specify pooling"
                )
    
    def _validate_cross_config_consistency(self):
        """Check consistency across config files."""
        # Check that task conv_types are valid
        tasks = self.configs.get("tasks", {})
        self.configs.get("model", {})
        
        for task_name, task_config in tasks.items():
            if "conv_type" in task_config:
                # Should be a valid conv type
                valid_types = ["gcn", "gat", "gin", "sage", "transformer", "pointnet", "temporal"]
                if task_config["conv_type"] not in valid_types:
                    self.issues.append(
                        f"Cross-config: Task '{task_name}' has invalid "
                        f"conv_type '{task_config['conv_type']}'"
                    )
        
        # Check HPO search space references valid config fields
        hpo = self.configs.get("hpo", {})
        if "search_space" in hpo:
            for param, param_config in hpo["search_space"].items():
                # Check if parameter exists in model or training config
                if param not in ["learning_rate", "batch_size", "hidden_dim", 
                                "num_layers", "dropout", "weight_decay"]:
                    self.issues.append(
                        f"hpo.yaml: Search parameter '{param}' not found in "
                        f"model or training configs"
                    )
    
    def print_report(self):
        """Print validation report."""
        is_valid, issues = self.validate_all()
        
        print("\n" + "="*60)
        print("AstroLab Configuration Validation Report")
        print("="*60)
        
        if is_valid:
            print("\n‚úÖ All configuration files are valid!")
        else:
            print(f"\n‚ùå Found {len(issues)} issues:\n")
            for i, issue in enumerate(issues, 1):
                print(f"{i}. {issue}")
        
        print("\n" + "="*60)
        
        # Print config summary
        print("\nüìã Configuration Summary:")
        print(f"  Surveys: {len(self.configs.get('surveys', {}))}")
        print(f"  Tasks: {len(self.configs.get('tasks', {}))}")
        print(f"  Data directory: {self.configs.get('data', {}).get('base_dir', 'not set')}")
        print(f"  Default model: {self.configs.get('model', {}).get('conv_type', 'not set')}")
        print(f"  Default epochs: {self.configs.get('training', {}).get('max_epochs', 'not set')}")


# CLI command for validation
if __name__ == "__main__":
    validator = ConfigValidator()
    validator.print_report()
